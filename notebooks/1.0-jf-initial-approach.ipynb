{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, make_scorer\n",
    "\n",
    "from sklearnext.over_sampling import SMOTE, GeometricSMOTE #scikit-learn extensions from IMS-ML-Lab\n",
    "from sklearnext.model_selection import ModelSearchCV\n",
    "from sklearnext.tools import report_model_search_results\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('tabexport2.csv', delimiter=';')\n",
    "\n",
    "new_columns = {}\n",
    "for col in df.columns[1:]:\n",
    "    new_columns[col] = col.replace('LC08_L1TP_204032_2015', '')[:4]+'_'+col[-1:]\n",
    "df = df.rename(columns=new_columns)\n",
    "\n",
    "report = pandas_profiling.ProfileReport(df)\n",
    "#report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing highly correlated data (alternative: PCA and what else?)\n",
    "df2 = df.drop(report.get_rejected_variables(),axis=1).copy()\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2.values[:,0]\n",
    "X = df2.values[:,1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "\n",
    "df2.groupby('class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "df2.groupby('class').size().max()/df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_search(X, y):\n",
    "    \"\"\"\n",
    "    Function built for convenience purposes. oversamplers, classifiers etc etc must be edited in the function itself,\n",
    "    if necessary.\n",
    "    \"\"\"\n",
    "    oversamplers = [\n",
    "        ('none', None),\n",
    "        ('smote', SMOTE()),\n",
    "        ('gsmote', GeometricSMOTE())\n",
    "    ]\n",
    "\n",
    "    classifiers = [\n",
    "        ('MLP', MLPClassifier(activation='logistic', \n",
    "                              solver='lbfgs', \n",
    "                              alpha=0.01,\n",
    "                              max_iter=1000000,\n",
    "                              verbose=True)),\n",
    "        ('DT', DecisionTreeClassifier()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('RF', RandomForestClassifier()),\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "    # missing parameters for DT, KNN and RF --> doing it later\n",
    "    pre_params = {\n",
    "        'smote': {'k_neighbours': [2, 3, 4, 5]},\n",
    "        'MLP': {\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "            'hidden_layer_sizes': [(64,64), (150), (75), (150, 150)],\n",
    "            'activation': ['relu', 'tanh', 'logistic'],\n",
    "        },\n",
    "        'gsmote': {\n",
    "            'k_neighbors': [2, 3, 4, 5],\n",
    "            'deformation_factor': [0.25, 0.50, 0.75],\n",
    "            'truncation_factor': [-0.5, 0.0, 0.5]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    param_grids = []\n",
    "    estimators = []\n",
    "    for oversampler in oversamplers:\n",
    "        for classifier in classifiers:\n",
    "            # sets up pipeline with name\n",
    "            name = f'{oversampler[0]}+{classifier[0]}'\n",
    "            estimators.append((name, Pipeline([oversampler, classifier])))\n",
    "\n",
    "            # sets up param grid for the estimator\n",
    "            param_grid = {}\n",
    "            if oversampler[0] in pre_params.keys(): \n",
    "                for key, value in pre_params[oversampler[0]].items():\n",
    "                    param_grid[f'{name}__{oversampler[0]}__{key}'] = value\n",
    "\n",
    "            if classifier[0]  in pre_params.keys(): \n",
    "                for key, value in pre_params[classifier[0]].items():\n",
    "                    param_grid[f'{name}__{classifier[0]}__{key}'] = value\n",
    "\n",
    "            param_grids.append(param_grid)\n",
    "\n",
    "\n",
    "    #auc = make_scorer(roc_auc_score,  greater_is_better=True, average='micro')\n",
    "    #acc = make_scorer(accuracy_score, greater_is_better=True, average='micro')\n",
    "    #rec = make_scorer(recall_score,   greater_is_better=True, average='micro')\n",
    "\n",
    "    model_search_cv = ModelSearchCV(\n",
    "        estimators=estimators, \n",
    "        param_grids=param_grids, \n",
    "    #    scoring=[acc, rec, auc], \n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "        refit=False, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model_search_cv.fit(X, y)\n",
    "\n",
    "    return model_search_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_search_cv = model_search(X,y)\n",
    "model_search_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is model_search_cv not including scores for different parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_model_search_results(model_search_cv)\n",
    "#model_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adopting a different procedure\n",
    "\n",
    "Going to try to develop one vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapper = lambda x, y: 'all' if x!=y else x\n",
    "g = df2.groupby('class').size()\n",
    "g.index = g.index.map(lambda x: remapper(x, 'C'))\n",
    "g.groupby('class').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "g.groupby('class').sum().loc['all'] / g.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "df3['class2'] = df3['class'].map(lambda x: remapper(x, 'C'))\n",
    "\n",
    "cols = list(df3.columns)\n",
    "cols.remove('class')\n",
    "cols.remove('class2')\n",
    "y = df3['class2'].values\n",
    "X = df3[cols].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_search_cv2 = model_search(X,y)\n",
    "report_model_search_results(model_search_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf3 = df3.drop(columns=['class2'])[df3['class']!='C'].copy()\n",
    "y = ndf3['class'].values\n",
    "X = ndf3[cols].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf3.groupby(['class']).size().max() / ndf3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_search_cv2 = model_search(X,y)\n",
    "report_model_search_results(model_search_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
